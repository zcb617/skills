#!/usr/bin/env python3
"""
TTG å½±è§†éŸ³ä¹åˆ†ç±»ç›‘æ§å™¨ - æ”¹è¿›ç‰ˆ
åŒ…å«æ›´è¯¦ç»†çš„ä¿¡æ¯æå–ï¼ˆæ ‡é¢˜å’Œå‘å¸ƒæ—¶é—´ï¼‰
"""

import requests
from bs4 import BeautifulSoup
import re
import time
import json
import os
from datetime import datetime
import subprocess


class TTGMediaMonitor:
    def __init__(self, config_file=None):
        self.base_url = "https://totheglory.im"
        self.media_url = "https://totheglory.im/browse.php?c=M"  # å½±è§†éŸ³ä¹åˆ†ç±»é“¾æ¥
        self.session = requests.Session()
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Referer': 'https://totheglory.im/',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        }
        self.session.headers.update(self.headers)
        
        # ä»é…ç½®æ–‡ä»¶åŠ è½½ç™»å½•ä¿¡æ¯
        if config_file and os.path.exists(config_file):
            self.load_credentials(config_file)
        else:
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        
        # å­˜å‚¨å·²çŸ¥çš„å¸–å­IDï¼Œç”¨äºæ£€æµ‹æ–°å†…å®¹
        self.known_posts_file = "/home/zhangcb/.openclaw/workspace/ttg-scraper/known_posts.json"
        self.known_posts = self.load_known_posts()
    
    def load_credentials(self, config_file):
        """ä»é…ç½®æ–‡ä»¶åŠ è½½ç™»å½•å‡­æ®"""
        with open(config_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            self.username = None
            self.password = None
            
            for line in lines:
                line = line.strip()
                if line.startswith('account='):
                    self.username = line.split('=', 1)[1]
                elif line.startswith('passwd='):
                    self.password = line.split('=', 1)[1]
    
    def load_known_posts(self):
        """åŠ è½½å·²çŸ¥çš„å¸–å­ID"""
        if os.path.exists(self.known_posts_file):
            with open(self.known_posts_file, 'r', encoding='utf-8') as f:
                return set(json.load(f))
        return set()
    
    def save_known_posts(self):
        """ä¿å­˜å·²çŸ¥çš„å¸–å­ID"""
        with open(self.known_posts_file, 'w', encoding='utf-8') as f:
            json.dump(list(self.known_posts), f, ensure_ascii=False, indent=2)
    
    def login(self):
        """ç™»å½•TTGç½‘ç«™"""
        # ç›´æ¥æäº¤ç™»å½•ï¼ˆä¸å…ˆè®¿é—®ä¸»é¡µï¼Œé¿å…ä¼šè¯é—®é¢˜ï¼‰
        login_data = {
            'username': self.username,
            'password': self.password,
            'passan': '',
            'passid': '0',
            'lang': '0'
        }
        
        # æäº¤ç™»å½•è¡¨å•
        login_response = self.session.post(f"{self.base_url}/takelogin.php", data=login_data)
        
        # æ£€æŸ¥ç™»å½•æ˜¯å¦æˆåŠŸï¼ˆæ£€æŸ¥my.phpï¼‰
        test_response = self.session.get(f"{self.base_url}/my.php")
        if "logout" in test_response.text.lower() and self.username in test_response.text:
            print("ç™»å½•æˆåŠŸ")
            return True
        else:
            print(f"ç™»å½•å¤±è´¥ã€‚my.phpçŠ¶æ€: {test_response.url}")
            return False
    
    def get_resource_details(self, torrent_id):
        """è·å–å•ä¸ªèµ„æºçš„è¯¦ç»†ä¿¡æ¯ï¼ˆæ ‡é¢˜å’Œå‘å¸ƒæ—¶é—´ï¼‰"""
        try:
            detail_url = f"{self.base_url}/details.php?id={torrent_id}"
            response = self.session.get(detail_url, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æå–æ ‡é¢˜
            title = ""
            
            # æ–¹æ³•1: æŸ¥æ‰¾åŒ…å«"æ ‡é¢˜"çš„è¡Œï¼ˆä½¿ç”¨text=å‚æ•°ï¼Œæ›´å…¼å®¹ï¼‰
            all_tds = soup.find_all('td')
            for td in all_tds:
                if 'æ ‡é¢˜' in td.get_text():
                    next_td = td.find_next_sibling('td')
                    if next_td:
                        title = next_td.get_text(strip=True)
                    break
            
            # æ–¹æ³•2: å¦‚æœæ–¹æ³•1å¤±è´¥ï¼Œå°è¯•ç›´æ¥æŸ¥æ‰¾h1æˆ–ç‰¹å®šçš„æ ‡é¢˜å…ƒç´ 
            if not title:
                h1_tag = soup.find('h1')
                if h1_tag:
                    title = h1_tag.get_text(strip=True)
            
            # æ–¹æ³•3: æŸ¥æ‰¾åŒ…å«èµ„æºçš„è¡Œ
            if not title:
                for row in soup.find_all('tr'):
                    cells = row.find_all('td')
                    for cell in cells:
                        if cell.find('a') and 'help' not in cell.get('href', ''):
                            text = cell.get_text(strip=True)
                            if len(text) > 10 and 'http' not in text:
                                title = text
                                break
                    if title:
                        break
            
            # æå–å‘å¸ƒæ—¶é—´
            publish_time = ""
            
            # æ–¹æ³•1: æŸ¥æ‰¾åŒ…å«æ—¶é—´ä¿¡æ¯çš„è¡Œ
            for td in all_tds:
                td_text = td.get_text()
                if re.match(r'\d{4}-\d{2}-\d{2}', td_text):
                    publish_time = td_text.strip()
                    break
            
            # æ–¹æ³•2: å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•æŸ¥æ‰¾ç‰¹å®šçš„classæˆ–id
            if not publish_time:
                date_pattern = r'\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}'
                matches = re.findall(date_pattern, response.text)
                if matches:
                    publish_time = matches[0]
            
            # æ–¹æ³•3: å¦‚æœä»ç„¶æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»ç§å­åˆ—è¡¨ä¸­æå–
            if not publish_time:
                for table in soup.find_all('table'):
                    for row in table.find_all('tr'):
                        cells = row.find_all('td')
                        if len(cells) >= 2:
                            cell_text = cells[0].get_text(strip=True)
                            if re.match(r'\d{4}-\d{2}-\d{2}', cell_text):
                                publish_time = cell_text
                                break
                    if publish_time:
                        break
            
            # å¦‚æœä»ç„¶æ²¡æœ‰æ‰¾åˆ°æ—¶é—´ï¼Œè®¾ç½®ä¸º"æœªçŸ¥"
            if not publish_time:
                publish_time = "æœªçŸ¥"
            
            # æ¸…ç†æ ‡é¢˜ï¼ˆç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼‰
            if title:
                title = re.sub(r'\s+', ' ', title)  # è§„èŒƒåŒ–ç©ºç™½å­—ç¬¦
                title = title[:200]  # é™åˆ¶æ ‡é¢˜é•¿åº¦
            
            return {
                'id': torrent_id,
                'title': title if title else f"èµ„æº #{torrent_id}",
                'url': detail_url,
                'publish_time': publish_time
            }
            
        except Exception as e:
            print(f"è·å–èµ„æº {torrent_id} è¯¦æƒ…æ—¶å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                'id': torrent_id,
                'title': f"èµ„æº #{torrent_id}",
                'url': f"{self.base_url}/details.php?id={torrent_id}",
                'publish_time': "è·å–å¤±è´¥"
            }
    
    def scrape_media_section(self):
        """çˆ¬å–å½±è§†éŸ³ä¹åˆ†ç±»é¡µé¢ç¬¬ä¸€é¡µ"""
        # ç™»å½•
        if not self.login():
            raise Exception("ç™»å½•å¤±è´¥ï¼Œæ— æ³•è®¿é—®å—ä¿æŠ¤çš„å†…å®¹")
        
        # è®¿é—®å½±è§†éŸ³ä¹åˆ†ç±»é¡µé¢ç¬¬ä¸€é¡µ
        response = self.session.get(self.media_url)
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ‰€æœ‰å¸–å­IDï¼ˆå› ä¸ºé¡µé¢å¯èƒ½ä½¿ç”¨JavaScriptåŠ¨æ€åŠ è½½ï¼‰
        all_ids = list(set(re.findall(r'/details\.php\?id=(\d+)', response.text)))
        all_ids.sort(key=int, reverse=True)
        
        # æŸ¥æ‰¾æ–°å¸–å­å¹¶è·å–è¯¦ç»†ä¿¡æ¯
        new_movies = []
        for i, torrent_id in enumerate(all_ids):
            if torrent_id not in self.known_posts:
                # è®¿é—®è¯¦æƒ…é¡µé¢è·å–æ ‡é¢˜å’Œå‘å¸ƒæ—¶é—´
                details = self.get_resource_details(torrent_id)
                new_movies.append(details)
                
                # æ·»åŠ çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡å¿«
                if i < len(all_ids) - 1:
                    time.sleep(0.5)
        
        return new_movies
    
    def check_new_content(self):
        """æ£€æŸ¥æ˜¯å¦æœ‰æ–°å†…å®¹"""
        try:
            # çˆ¬å–å†…å®¹
            new_movies = self.scrape_media_section()
            
            # æ›´æ–°å·²çŸ¥å¸–å­åˆ—è¡¨
            for movie in new_movies:
                self.known_posts.add(movie['id'])
            
            # ä¿å­˜æ›´æ–°åçš„å·²çŸ¥å¸–å­åˆ—è¡¨
            self.save_known_posts()
            
            return new_movies
            
        except Exception as e:
            print(f"æ£€æŸ¥æ–°å†…å®¹æ—¶å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            return []
    
    def send_notifications(self, new_movies):
        """å‘é€é€šçŸ¥åˆ°é’‰é’‰å’ŒWhatsApp"""
        if not new_movies:
            return
        
        # æ„å»ºé€šçŸ¥æ¶ˆæ¯ï¼ŒåŒ…å«æ ‡é¢˜ã€å‘å¸ƒæ—¶é—´å’Œé“¾æ¥
        message_lines = [f"ğŸ¬ å‘ç° {len(new_movies)} ä¸ªæ–°ç”µå½±/éŸ³ä¹èµ„æº:"]
        for movie in new_movies:
            publish_info = f"[{movie['publish_time']}]" if movie.get('publish_time') not in ["æœªçŸ¥", "è·å–å¤±è´¥"] else ""
            message_lines.append(f"â€¢ {movie['title']} {publish_info}")
            message_lines.append(f"  {movie['url']}")
        
        message = "\\n".join(message_lines)
        
        print(f"å‡†å¤‡å‘é€é€šçŸ¥:\\n{message}")
        
        # å‘é€é’‰é’‰é€šçŸ¥
        try:
            cmd_dingtalk = [
                "bash", "-c",
                f'source /etc/profile && source /home/zhangcb/.nvm/nvm.sh && cd /home/zhangcb/.nvm/versions/node/v24.13.0/lib/node_modules/openclaw && openclaw message send --channel dingtalk --target "å°å¼ åŒå­¦" --message "{message}"'
            ]
            result_dingtalk = subprocess.run(cmd_dingtalk, capture_output=True, text=True, timeout=30)
            if result_dingtalk.returncode == 0:
                print("é’‰é’‰é€šçŸ¥å‘é€æˆåŠŸ")
            else:
                print(f"é’‰é’‰é€šçŸ¥å‘é€å¤±è´¥: {result_dingtalk.stderr}")
        except Exception as e:
            print(f"å‘é€é’‰é’‰é€šçŸ¥æ—¶å‡ºé”™: {str(e)}")
        
        # å‘é€WhatsAppé€šçŸ¥
        try:
            cmd_whatsapp = [
                "bash", "-c",
                f'source /etc/profile && source /home/zhangcb/.nvm/nvm.sh && cd /home/zhangcb/.nvm/versions/node/v24.13.0/lib/node_modules/openclaw && openclaw message send --channel whatsapp --target +8618605738770 --message "{message}"'
            ]
            result_whatsapp = subprocess.run(cmd_whatsapp, capture_output=True, text=True, timeout=30)
            if result_whatsapp.returncode == 0:
                print("WhatsAppé€šçŸ¥å‘é€æˆåŠŸ")
            else:
                print(f"WhatsAppé€šçŸ¥å‘é€å¤±è´¥: {result_whatsapp.stderr}")
        except Exception as e:
            print(f"å‘é€WhatsAppé€šçŸ¥æ—¶å‡ºé”™: {str(e)}")
    
    def run_check(self):
        """æ‰§è¡Œå•æ¬¡æ£€æŸ¥"""
        print(f"[{datetime.now()}] å¼€å§‹æ£€æŸ¥TTGå½±è§†éŸ³ä¹åˆ†ç±»æ–°å†…å®¹...")
        
        try:
            new_movies = self.check_new_content()
            
            if new_movies:
                print(f"å‘ç° {len(new_movies)} ä¸ªæ–°èµ„æº!")
                self.send_notifications(new_movies)
                return True
            else:
                print("æš‚æ— æ–°èµ„æº")
                return False
                
        except Exception as e:
            print(f"æ£€æŸ¥è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            return False


def main():
    """ä¸»å‡½æ•°"""
    try:
        monitor = TTGMediaMonitor("/home/zhangcb/.totheglory")
        monitor.run_check()
    except Exception as e:
        print(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")


if __name__ == "__main__":
    main()